
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% main entrance for owh
% 1. load data
% 2. compute hash code using different methods
% 3. learn weights
% 4. evaluation


%% load raw data
% regular ml data format, treat as two groups, one for the same class, the
% other for all different ones
traindata = [];
trainlabel = [];

% dataset_name dataset_folder
datasets = cell(4,2);
datasets{1,1} = 'dummy'; datasets{1,2} = '';
datasets{2,1} = 'CIFAR10';  datasets{2,2} = 'F:\Datasets\Recognition\CIFAR-10\cifar-10-binary\';

use_data = 2;
if use_data == 1
    % use nearest neighbor to set positive samples
    trainlabel = ones(size(traindata,1), 1) * 2;
    [traindata, traindistmat] = gen_dummy_data(300, 100);
    neighbor_num = 100;
    [sorted_dist, sorted_idx] = sort(traindist, 2);
    similar_bound = mean( sorted_dist(:, neighbor_num) );
    % !not clear how to do label here!
    similar_ids = sorted_idx(traindistmat < similar_bound);
    trainlabel(similar_ids, 1) = 1;
else if use_data == 2
        % load gist from file
        traindata = load([datasets{2,2} 'train_1_gist.txt']);
        trainlabel = load([datasets{2,2} 'train_1_label.txt']);
    end
end

% make label starts from 1
trainlabel = trainlabel + 1;

% separate into groups with same labels
unique_label_num = length( unique(trainlabel) );
train_groups = cell(unique_label_num, 1);
for i=1:unique_label_num
    train_groups{i,1} = find(trainlabel == i); 
end


%% compute base hash code

% general binary code params
code_params.nbits = 32;

% code name | code path
codetypes = cell(4,2);
codetypes{1,1} = 'SH'; codetypes{1,2} = '../SH/';
codetypes{2,1} = 'ITQ'; codetypes{2,2} = '../ITQ/';
codetypes{3,1} = 'LSH'; codetypes{3,2} = '';

code_type = 1;
traincodes = [];

% add code path
addpath(genpath(codetypes{code_type, 2}));
if code_type == 1
    % learn sh codes
    sh_params.nbits = code_params.nbits;
    sh_params = trainSH(traindata, sh_params);
    [traincodes, U] = compressSH(traindata, sh_params);
else if codetype == 2
        % learn itq
    end
end


%% generate similarity pairs
% format: (samp_id, sim_id, dis_id)

% randomly select subset from same class as positive, the rest as negative
triplet_num = 1000;
sim_triplets = zeros(triplet_num, 6);
for i=1:triplet_num
    % select a sample
    samp_cls_id = int(randsample(unique_label_num, 1));
    samp_obj_id = int(randsample(train_groups{samp_cls_id},1));
    % select similar sample from same class
    sim_cls_id = samp_cls_id;
    sim_obj_id = 0;
    while 1
        temp_obj_id = int(randsample(train_groups{samp_cls_id},1));
        if temp_obj_id ~= samp_obj_id
            sim_obj_id = temp_obj_id;
            break;
        end
    end
    % select dissimilar sample from different classes
    dis_cls_id = 0;
    while 1
        temp_cls_id = int(randsample(unique_label_num,1));
        if temp_cls_id ~= samp_cls_id
            dis_cls_id = temp_obj_id;
            break;
        end
    end
    dis_obj_id = int(randsample(train_groups{dis_cls_id},1));
    % add to collection
    sim_triplets(i,:) = [samp_cls_id, samp_obj_id, sim_cls_id, sim_obj_id, dis_cls_id, dis_obj_id];
end

% pre_compute hamming distance vector for selected pairs
% to cope with svm code, we 


%% learn weights using ranksvm formulation
% now use relative attribute code

% construct parameters for svm code
svm_opt.lin_cg = 0; % not use conjugate gradient
svm_opt.iter_max_Newton = 20;   % Maximum number of Newton steps
svm_opt.prec = 0.000001;    %   prec: Stopping criterion
w_0 = zeros(1,1);   % initial weights

% construct ordering and similarity matrix
O = zeros(triplet_num, size(traincodes, 1));
S = zeros(triplet_num, size(traincodes, 1));
% Each row of O should contain exactly one +1 and one -1.
for i=1:triplet_num
    
    
    
end


w = ranksvm_with_sim(traincodes,O,S,C_O,C_S,w,opt);


